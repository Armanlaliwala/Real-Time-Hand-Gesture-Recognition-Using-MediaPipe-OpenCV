âœ‹ Real-Time Hand Gesture Recognition Using MediaPipe & OpenCV


ğŸš€ Project Overview
This project uses MediaPipe and OpenCV to recognize hand gestures in real-time from a live camera feed.
It supports the detection of predefined gestures including:

ğŸ‘ Thumbs Up

ğŸ‘ Thumbs Down

âœŠ Fist

The system:

ğŸ¯ Detects and classifies hand gestures using landmarks.

ğŸ¥ Saves the processed video feed using the H.264 codec for smooth playback and wide compatibility.

ğŸ§  Can be integrated into applications such as touchless interfaces, smart homes, and gesture-controlled systems.

âš™ï¸ Features
âœ… Real-time gesture recognition using webcam input.
âœ… Detects gestures: Thumbs Up, Thumbs Down, and Fist.
âœ… Saves annotated output video with high-quality encoding.
âœ… Clean and extensible codebase to add more gestures.
âœ… Supports external cameras (e.g., mobile camera via DroidCam/Iriun).

ğŸ› ï¸ Tech Stack
Language: Python

Libraries:

MediaPipe â†’ For hand landmark tracking.

OpenCV â†’ For video capture, drawing, and output.

NumPy â†’ For gesture logic and classification.

ğŸ“ Installation
1. Clone the Repository
bash
Copy
Edit
git clone https://github.com/Armanlaliwala/Real-Time-Hand-Gesture-Recognition-Using-MediaPipe-OpenCV.git
cd Real-Time-Hand-Gesture-Recognition-Using-MediaPipe-OpenCV
2. Create and Activate a Virtual Environment
Windows:
bash
Copy
Edit
python -m venv env
env\Scripts\activate
Linux/Mac:
bash
Copy
Edit
python3 -m venv env
source env/bin/activate
3. Install Required Dependencies
bash
Copy
Edit
pip install -r requirements.txt
ğŸš€ Usage
ğŸ–¥ï¸ Run Gesture Recognition
To start the gesture recognition using your camera:

bash
Copy
Edit
python gesture_recognition.py
The output video will be saved as:

Copy
Edit
gesture_output.mp4
ğŸ” How It Works
ğŸ§  Gesture Classification Logic
Uses MediaPipe to detect hand landmarks in real time.

Applies logical conditions based on the relative position of fingers and thumb for each gesture:

Thumbs Up â†’ Thumb up, all other fingers folded.

Thumbs Down â†’ Thumb down, others folded.

Fist â†’ All fingers folded.

ğŸ¥ Video Recording
The video is encoded using H.264, offering:

Smooth FPS

High compatibility

Small file size

ğŸ“¸ Demo
âœ… Real-time detection of gestures with live feedback:
(Include GIF or image demo here)

ğŸ™Œ Applications
ğŸ¤– AI-powered gesture control systems

ğŸ  Smart home automation

ğŸ§â€â™‚ï¸ Sign language recognition

ğŸ® Touchless interfaces and VR/AR experiences

ğŸ™ Acknowledgments
MediaPipe â†’ For powerful hand tracking APIs.

OpenCV â†’ For real-time video processing and rendering.

NumPy â†’ For efficient computation and logic.

ğŸ”— Project Links
ğŸ”¥ GitHub: https://github.com/Armanlaliwala/Real-Time-Hand-Gesture-Recognition-Using-MediaPipe-OpenCV

ğŸ“¢ LinkedIn Post: https://www.linkedin.com/posts/armanlaliwala_ai-machinelearning-artificialintelligence-activity-7311607183916384256-cp9m?utm_source=share&utm_medium=member_desktop&rcm=ACoAAC8UXJgBzh3CZnnoGRqLRShPaW7Tiw-ZjRc

ğŸ¤ Contribute & Support
If this project helped you or sparked inspiration:

â­ Star the repo

ğŸ´ Fork it

ğŸ’¬ Share your ideas or suggestions!

ğŸ‘¨â€ğŸ’» About Me
Iâ€™m Arman Laliwala, a final-year Computer Engineering student passionate about AI/ML, building intelligent solutions for a better tomorrow.
ğŸ› ï¸ Looking for collaborations on AI/ML projects? Letâ€™s connect!

ğŸ“¬ Letâ€™s Connect
ğŸ”— YouTube: https://lnkd.in/dyxVcX9T
ğŸ”— GitHub: https://lnkd.in/dS_tkrjw
ğŸ”— LinkedIn: https://lnkd.in/dzp5Bupn
ğŸ”— Instagram: https://lnkd.in/dPCF3DC4
ğŸ”— Medium: https://lnkd.in/dWfZBHNM
ğŸ”— Kaggle: https://lnkd.in/dewnEswf

ğŸ“¢ Hashtags
#AI #MachineLearning #ArtificialIntelligence #DataScience #Python #GestureRecognition #OpenCV #MediaPipe #SmartHome #SignLanguage #VR #AR #HumanComputerInteraction
#armanlaliwala #laliwala #arman #ArmanLaliwala

